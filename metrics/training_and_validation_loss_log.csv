Epoch,Training Loss,Validation Loss
1,2.2188823141995266,1.5983985142242274
2,1.4353082679079834,1.097297469980618
3,1.0322199957610587,0.7975120995877057
4,0.7810485978451001,0.5992249180755672
5,0.595496412741362,0.4723942023674412
6,0.45797446308404033,0.370244362760754
7,0.36690548817301993,0.30884797331055946
8,0.30007539160505553,0.2606008996272228
9,0.24139289520460472,0.22150548345260543
10,0.20555097036636794,0.19682208998624742
11,0.1686449056634536,0.17908341368693395
12,0.1429481566745854,0.16341123338127453
13,0.13380030878769927,0.14046644069772413
14,0.11766760218227228,0.13410366594945713
15,0.09828790230400992,0.1220405424597877
16,0.09197084932483336,0.12040586424605733
17,0.0805245997141716,0.10597442505748932
18,0.07429796687365901,0.09869293937977602
19,0.07124276070982306,0.09192761373306631
20,0.06403108175910084,0.0907959782652083
